{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動作確認\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "label_list = []\n",
    "for i in range(10):\n",
    "    label_list.append(str(i))\n",
    "for i in range(65, 91):\n",
    "    label_list.append(str(chr(i)))\n",
    "for i in range(97, 123):\n",
    "    label_list.append(str(chr(i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataset 697932\n",
      "20\n",
      "torch.Size([50, 1, 64, 64])\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21b80afa9d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = torchvision.datasets.EMNIST(\n",
    "    root='./data',\n",
    "    split='byclass',\n",
    "    transform=tt.Compose([\n",
    "                    lambda img: tt.functional.rotate(img, -90),\n",
    "                    lambda img: tt.functional.hflip(img),\n",
    "                    tt.ToTensor(),\n",
    "                    tt.Resize(64)\n",
    "                ]),\n",
    "    download=True\n",
    "    )\n",
    "print(\"size of dataset\", len(dataset))\n",
    "train_dataset, _ = torch.utils.data.random_split(dataset, [1000, 696932])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                         batch_size=50,\n",
    "                         shuffle=True)\n",
    "print(len(train_dataloader))\n",
    "# 動作の確認\n",
    "batch_iterator = iter(train_dataloader)  # イテレータに変換\n",
    "imges, label = next(batch_iterator)  # 1番目の要素を取り出す\n",
    "print(imges.size())  # torch.Size([64, 1, 64, 64])\n",
    "print(label_list[int(label[0])])\n",
    "plt.imshow(imges[0][0], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベル学習のための関数\n",
    "# One-hotエンコーディング\n",
    "def onehot_encode(label, device, num_class=62):\n",
    "    eye = torch.eye(num_class, device=device)\n",
    "    # サイズ(batch_size, num_class, 1, 1)のテンソル\n",
    "    return eye[label].view(-1, num_class, 1, 1)\n",
    "\n",
    "# 画像とラベルの連結\n",
    "def concat_image_label(image, label, device, num_class=62):\n",
    "    # 画像tensor sizeを取得\n",
    "    batch_size, _, height, width = image.shape\n",
    "\n",
    "    # ラベルをOne-hotベクトル化\n",
    "    one_hot_label = onehot_encode(label, device)\n",
    "\n",
    "    # 画像のサイズに合わせるようにラベルを拡張\n",
    "    one_hot_label = one_hot_label.expand(batch_size, num_class, height, width)\n",
    "\n",
    "    # 画像とラベルをチェンネル方向(dim=1)で連結\n",
    "    return torch.cat((image, one_hot_label), dim=1)\n",
    "\n",
    "# ノイズとラベルの連結\n",
    "def concat_noise_label(noise, label, device):\n",
    "    one_hot_label =onehot_encode(label, device)\n",
    "    return torch.cat((noise, one_hot_label), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim=20, image_size=64):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, image_size * 8,\n",
    "                               kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(image_size * 8),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * 8, image_size * 4,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size * 4),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * 4, image_size * 2,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size * 2),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * 2, image_size,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.last = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size, 1, kernel_size=4,\n",
    "                               stride=2, padding=1),\n",
    "            nn.Tanh())\n",
    "        # 注意：白黒画像なので出力チャネルは1つだけ\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.layer1(z)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.last(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, nch=1, z_dim=20, image_size=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(nch, image_size, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        # 注意：白黒画像なので入力チャンネルは１つだけ\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(image_size, image_size*2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(image_size*2, image_size*4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(image_size*4, image_size*8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "            \n",
    "        self.last = nn.Conv2d(image_size*8, 1, kernel_size=4, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.last(out)\n",
    "        \n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cpu\n",
      "ネットワークの初期化の完了\n"
     ]
    }
   ],
   "source": [
    "# ネットワークの初期化\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        # Conv2dとConvTranspose2dの初期化\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        # BatchNorm2dの初期化\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "# パラメータをハードコーディング\n",
    "z_dim = 100\n",
    "mini_batch_size = 50\n",
    "\n",
    "\n",
    "# GPUが使えるかを確認\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用デバイス：\", device)\n",
    "\n",
    "# ネットワークをGPUへ\n",
    "net_G = Generator(z_dim=z_dim+62).to(device)\n",
    "net_D = Discriminator(nch=1+62).to(device)\n",
    "\n",
    "# 初期化の実施\n",
    "net_G.apply(weights_init)\n",
    "net_D.apply(weights_init)\n",
    "print(\"ネットワークの初期化の完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.utils as vutils\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# モデルを学習させる関数を作成\n",
    "def train_model(net_G, net_D, dataloader, num_epochs, mini_batch_size, z_dim, device, outf):\n",
    "\n",
    "    # 最適化手法の設定\n",
    "    g_lr, d_lr = 0.0001, 0.0004\n",
    "    beta1, beta2 = 0.0, 0.9\n",
    "    g_optimizer = torch.optim.Adam(net_G.parameters(), g_lr, [beta1, beta2])\n",
    "    d_optimizer = torch.optim.Adam(net_D.parameters(), d_lr, [beta1, beta2])\n",
    "\n",
    "    # 誤差関数を定義\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "\n",
    "    net_G.train()  # モデルを訓練モードに\n",
    "    net_D.train()  # モデルを訓練モードに\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 画像の枚数\n",
    "    batch_size = dataloader.batch_size\n",
    "\n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        epoch_g_loss = 0.0  # epochの損失和\n",
    "        epoch_d_loss = 0.0  # epochの損失和\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-------------')\n",
    "        print('（train）')\n",
    "\n",
    "        # データローダーからminibatchずつ取り出すループ\n",
    "        for batch, data in enumerate(dataloader):\n",
    "            imges = data[0]\n",
    "            label = data[1]\n",
    "            # --------------------\n",
    "            # 1. Discriminatorの学習\n",
    "            # --------------------\n",
    "            # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n",
    "            if imges.size()[0] == 1:\n",
    "                continue\n",
    "\n",
    "            # GPUが使えるならGPUにデータを送る\n",
    "            imges = imges.to(device)\n",
    "            label = label.to(device)\n",
    "            real_image_label = concat_image_label(imges, label, device)\n",
    "\n",
    "            net_D.zero_grad()\n",
    "            # 正解ラベルと偽ラベルを作成\n",
    "            # epochの最後のイテレーションはミニバッチの数が少なくなる\n",
    "            mini_batch_size = imges.size()[0]\n",
    "            noise = torch.randn(mini_batch_size, z_dim, 1 ,1, device=device)\n",
    "            fake_label = torch.randint(62, (mini_batch_size,), dtype=torch.long, device=device)\n",
    "            fake_noise_label = concat_noise_label(noise, fake_label, device) #ノイズとラベルを連結\n",
    "\n",
    "            #識別の目標値を設定\n",
    "            real_target = torch.full((mini_batch_size,), 1., device=device) #本物は1\n",
    "            fake_target = torch.full((mini_batch_size,), 0., device=device) #偽物は0\n",
    "\n",
    "\n",
    "            # 本物画像に対する損失値\n",
    "            d_out_real = net_D(real_image_label)\n",
    "            d_loss_real = criterion(d_out_real, real_target.float())\n",
    "\n",
    "            # 偽物画像を生成し、偽物画像に対する損失値\n",
    "            fake_image = net_G(fake_noise_label)\n",
    "            # 偽物画像とラベルを結合\n",
    "            fake_image_label = concat_image_label(fake_image, fake_label, device)\n",
    "            d_out_fake = net_D(fake_image_label.detach())\n",
    "            d_loss_fake = criterion(d_out_fake, fake_target.float())\n",
    "\n",
    "            # net_Dの損失値の合計\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "            # バックプロパゲーション\n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # --------------------\n",
    "            # 2. Generatorの学習\n",
    "            # --------------------\n",
    "            # 偽の画像を生成して判定\n",
    "            net_G.zero_grad()\n",
    "\n",
    "            d_out_fake = net_D(fake_image_label)\n",
    "            # 誤差を計算\n",
    "            g_loss = criterion(d_out_fake, label.float())\n",
    "\n",
    "            # バックプロパゲーション\n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            # --------------------\n",
    "            # 3. 記録\n",
    "            # --------------------\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            iteration += 1\n",
    "\n",
    "        # epochのphaseごとのlossと正解率\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_D_Loss:{:.4f} ||Epoch_G_Loss:{:.4f}'.format(\n",
    "            epoch, epoch_d_loss/batch_size, epoch_g_loss/batch_size))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        \n",
    "        # 学習率の推移の保存\n",
    "        writer.add_scalar('Epoch_D_Loss', epoch_d_loss/batch_size, epoch)\n",
    "        writer.add_scalar('Epoch_G_Loss', epoch_g_loss/batch_size, epoch)\n",
    "\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            for i in range(62):\n",
    "                sample_noise = torch.randn(62, z_dim, 1 ,1, device=device)\n",
    "                sample_label = [i for i in range(62)] #0~9の値の繰り返す（5回）\n",
    "                sample_label = torch.tensor(sample_label, dtype=torch.long, device=device) #torch.longはint64を指す\n",
    "                fake_noise_label = concat_noise_label(sample_noise, sample_label, device) #ノイズとラベルを連結\n",
    "                fake_image = net_G(fake_noise_label)\n",
    "                vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1, i), normalize=True, nrow=10)\n",
    "\n",
    "\n",
    "        # モデルの保存\n",
    "        if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "            torch.save(net_D, outf + \"net_D.pth\")\n",
    "            torch.save(net_G, outf + \"net_G.pth\")\n",
    "\n",
    "        t_epoch_start = time.time()\n",
    "        \n",
    "\n",
    "    return net_G, net_D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Epoch 0/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 0 || Epoch_D_Loss:0.4763 ||Epoch_G_Loss:4.8792\n",
      "timer:  56.9318 sec.\n",
      "-------------\n",
      "Epoch 1/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 1 || Epoch_D_Loss:0.4165 ||Epoch_G_Loss:8.2477\n",
      "timer:  54.4274 sec.\n",
      "-------------\n",
      "Epoch 2/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 2 || Epoch_D_Loss:0.3341 ||Epoch_G_Loss:12.4119\n",
      "timer:  59.2121 sec.\n",
      "-------------\n",
      "Epoch 3/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 3 || Epoch_D_Loss:0.3949 ||Epoch_G_Loss:12.0019\n",
      "timer:  54.9664 sec.\n",
      "-------------\n",
      "Epoch 4/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 4 || Epoch_D_Loss:0.3571 ||Epoch_G_Loss:12.5096\n",
      "timer:  53.8833 sec.\n",
      "-------------\n",
      "Epoch 5/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 5 || Epoch_D_Loss:0.3360 ||Epoch_G_Loss:14.4542\n",
      "timer:  56.8513 sec.\n",
      "-------------\n",
      "Epoch 6/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 6 || Epoch_D_Loss:0.2950 ||Epoch_G_Loss:18.7130\n",
      "timer:  56.2835 sec.\n",
      "-------------\n",
      "Epoch 7/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 7 || Epoch_D_Loss:0.2626 ||Epoch_G_Loss:18.1149\n",
      "timer:  55.2767 sec.\n",
      "-------------\n",
      "Epoch 8/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 8 || Epoch_D_Loss:0.2687 ||Epoch_G_Loss:20.9096\n",
      "timer:  54.8790 sec.\n",
      "-------------\n",
      "Epoch 9/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 9 || Epoch_D_Loss:0.2509 ||Epoch_G_Loss:22.9037\n",
      "timer:  54.9065 sec.\n",
      "-------------\n",
      "Epoch 10/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 10 || Epoch_D_Loss:0.2333 ||Epoch_G_Loss:22.3214\n",
      "timer:  56.0431 sec.\n",
      "-------------\n",
      "Epoch 11/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 11 || Epoch_D_Loss:0.2183 ||Epoch_G_Loss:24.4894\n",
      "timer:  64.0791 sec.\n",
      "-------------\n",
      "Epoch 12/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 12 || Epoch_D_Loss:0.2029 ||Epoch_G_Loss:24.5449\n",
      "timer:  66.4006 sec.\n",
      "-------------\n",
      "Epoch 13/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 13 || Epoch_D_Loss:0.2018 ||Epoch_G_Loss:29.0443\n",
      "timer:  69.6577 sec.\n",
      "-------------\n",
      "Epoch 14/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 14 || Epoch_D_Loss:0.1860 ||Epoch_G_Loss:29.8020\n",
      "timer:  67.8018 sec.\n",
      "-------------\n",
      "Epoch 15/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 15 || Epoch_D_Loss:0.1714 ||Epoch_G_Loss:31.7857\n",
      "timer:  64.9100 sec.\n",
      "-------------\n",
      "Epoch 16/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 16 || Epoch_D_Loss:0.1594 ||Epoch_G_Loss:32.0944\n",
      "timer:  63.1319 sec.\n",
      "-------------\n",
      "Epoch 17/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 17 || Epoch_D_Loss:0.1609 ||Epoch_G_Loss:34.4715\n",
      "timer:  61.3825 sec.\n",
      "-------------\n",
      "Epoch 18/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 18 || Epoch_D_Loss:0.1383 ||Epoch_G_Loss:36.4436\n",
      "timer:  59.8029 sec.\n",
      "-------------\n",
      "Epoch 19/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 19 || Epoch_D_Loss:0.1293 ||Epoch_G_Loss:36.9416\n",
      "timer:  62.5181 sec.\n",
      "-------------\n",
      "Epoch 20/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 20 || Epoch_D_Loss:0.1364 ||Epoch_G_Loss:40.0954\n",
      "timer:  56.2203 sec.\n",
      "-------------\n",
      "Epoch 21/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 21 || Epoch_D_Loss:0.1398 ||Epoch_G_Loss:40.7330\n",
      "timer:  57.5611 sec.\n",
      "-------------\n",
      "Epoch 22/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 22 || Epoch_D_Loss:0.1012 ||Epoch_G_Loss:38.8702\n",
      "timer:  57.2735 sec.\n",
      "-------------\n",
      "Epoch 23/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 23 || Epoch_D_Loss:0.1072 ||Epoch_G_Loss:44.2587\n",
      "timer:  55.6173 sec.\n",
      "-------------\n",
      "Epoch 24/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 24 || Epoch_D_Loss:0.1264 ||Epoch_G_Loss:41.5081\n",
      "timer:  57.6627 sec.\n",
      "-------------\n",
      "Epoch 25/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 25 || Epoch_D_Loss:0.1038 ||Epoch_G_Loss:41.3899\n",
      "timer:  55.7550 sec.\n",
      "-------------\n",
      "Epoch 26/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 26 || Epoch_D_Loss:0.1004 ||Epoch_G_Loss:42.4338\n",
      "timer:  55.9762 sec.\n",
      "-------------\n",
      "Epoch 27/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 27 || Epoch_D_Loss:0.1014 ||Epoch_G_Loss:46.8216\n",
      "timer:  53.9527 sec.\n",
      "-------------\n",
      "Epoch 28/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 28 || Epoch_D_Loss:0.0724 ||Epoch_G_Loss:46.9693\n",
      "timer:  58.0251 sec.\n",
      "-------------\n",
      "Epoch 29/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 29 || Epoch_D_Loss:0.1090 ||Epoch_G_Loss:43.8506\n",
      "timer:  56.6597 sec.\n",
      "-------------\n",
      "Epoch 30/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 30 || Epoch_D_Loss:0.1092 ||Epoch_G_Loss:48.4140\n",
      "timer:  56.5396 sec.\n",
      "-------------\n",
      "Epoch 31/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 31 || Epoch_D_Loss:0.0498 ||Epoch_G_Loss:51.1153\n",
      "timer:  55.1750 sec.\n",
      "-------------\n",
      "Epoch 32/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 32 || Epoch_D_Loss:0.1224 ||Epoch_G_Loss:50.1757\n",
      "timer:  54.7803 sec.\n",
      "-------------\n",
      "Epoch 33/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 33 || Epoch_D_Loss:0.0645 ||Epoch_G_Loss:52.4012\n",
      "timer:  58.9702 sec.\n",
      "-------------\n",
      "Epoch 34/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 34 || Epoch_D_Loss:0.0736 ||Epoch_G_Loss:52.0881\n",
      "timer:  60.8492 sec.\n",
      "-------------\n",
      "Epoch 35/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 35 || Epoch_D_Loss:0.0843 ||Epoch_G_Loss:55.6446\n",
      "timer:  63.4823 sec.\n",
      "-------------\n",
      "Epoch 36/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 36 || Epoch_D_Loss:0.0866 ||Epoch_G_Loss:53.7584\n",
      "timer:  63.8403 sec.\n",
      "-------------\n",
      "Epoch 37/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 37 || Epoch_D_Loss:0.0707 ||Epoch_G_Loss:54.8191\n",
      "timer:  59.0313 sec.\n",
      "-------------\n",
      "Epoch 38/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 38 || Epoch_D_Loss:0.0785 ||Epoch_G_Loss:58.2033\n",
      "timer:  65.6521 sec.\n",
      "-------------\n",
      "Epoch 39/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 39 || Epoch_D_Loss:0.0559 ||Epoch_G_Loss:58.6444\n",
      "timer:  60.7496 sec.\n",
      "-------------\n",
      "Epoch 40/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 40 || Epoch_D_Loss:0.1149 ||Epoch_G_Loss:54.6702\n",
      "timer:  61.0817 sec.\n",
      "-------------\n",
      "Epoch 41/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 41 || Epoch_D_Loss:0.0290 ||Epoch_G_Loss:57.9810\n",
      "timer:  66.4718 sec.\n",
      "-------------\n",
      "Epoch 42/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 42 || Epoch_D_Loss:0.1026 ||Epoch_G_Loss:55.8287\n",
      "timer:  72.8200 sec.\n",
      "-------------\n",
      "Epoch 43/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 43 || Epoch_D_Loss:0.0476 ||Epoch_G_Loss:60.4919\n",
      "timer:  71.9158 sec.\n",
      "-------------\n",
      "Epoch 44/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 44 || Epoch_D_Loss:0.0694 ||Epoch_G_Loss:56.4173\n",
      "timer:  72.0232 sec.\n",
      "-------------\n",
      "Epoch 45/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 45 || Epoch_D_Loss:0.0548 ||Epoch_G_Loss:61.0655\n",
      "timer:  69.0848 sec.\n",
      "-------------\n",
      "Epoch 46/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 46 || Epoch_D_Loss:0.1082 ||Epoch_G_Loss:58.8122\n",
      "timer:  64.9794 sec.\n",
      "-------------\n",
      "Epoch 47/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 47 || Epoch_D_Loss:0.0226 ||Epoch_G_Loss:60.4061\n",
      "timer:  56.3910 sec.\n",
      "-------------\n",
      "Epoch 48/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 48 || Epoch_D_Loss:0.0876 ||Epoch_G_Loss:60.1611\n",
      "timer:  59.6568 sec.\n",
      "-------------\n",
      "Epoch 49/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 49 || Epoch_D_Loss:0.0614 ||Epoch_G_Loss:61.5720\n",
      "timer:  54.9784 sec.\n",
      "-------------\n",
      "Epoch 50/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 50 || Epoch_D_Loss:0.0577 ||Epoch_G_Loss:59.0479\n",
      "timer:  55.5470 sec.\n",
      "-------------\n",
      "Epoch 51/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 51 || Epoch_D_Loss:0.0881 ||Epoch_G_Loss:60.4387\n",
      "timer:  53.2813 sec.\n",
      "-------------\n",
      "Epoch 52/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 52 || Epoch_D_Loss:0.0662 ||Epoch_G_Loss:59.7628\n",
      "timer:  53.3964 sec.\n",
      "-------------\n",
      "Epoch 53/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 53 || Epoch_D_Loss:0.0679 ||Epoch_G_Loss:64.0036\n",
      "timer:  51.9056 sec.\n",
      "-------------\n",
      "Epoch 54/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 54 || Epoch_D_Loss:0.0780 ||Epoch_G_Loss:56.4908\n",
      "timer:  51.5445 sec.\n",
      "-------------\n",
      "Epoch 55/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 55 || Epoch_D_Loss:0.0645 ||Epoch_G_Loss:62.0868\n",
      "timer:  51.4903 sec.\n",
      "-------------\n",
      "Epoch 56/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 56 || Epoch_D_Loss:0.0682 ||Epoch_G_Loss:58.1445\n",
      "timer:  52.8730 sec.\n",
      "-------------\n",
      "Epoch 57/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 57 || Epoch_D_Loss:0.0454 ||Epoch_G_Loss:59.4730\n",
      "timer:  57.0319 sec.\n",
      "-------------\n",
      "Epoch 58/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 58 || Epoch_D_Loss:0.0879 ||Epoch_G_Loss:58.7061\n",
      "timer:  54.3818 sec.\n",
      "-------------\n",
      "Epoch 59/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 59 || Epoch_D_Loss:0.1048 ||Epoch_G_Loss:60.1733\n",
      "timer:  54.7048 sec.\n",
      "-------------\n",
      "Epoch 60/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 60 || Epoch_D_Loss:0.0491 ||Epoch_G_Loss:57.6281\n",
      "timer:  53.9350 sec.\n",
      "-------------\n",
      "Epoch 61/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 61 || Epoch_D_Loss:0.0572 ||Epoch_G_Loss:61.7482\n",
      "timer:  53.8037 sec.\n",
      "-------------\n",
      "Epoch 62/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 62 || Epoch_D_Loss:0.0810 ||Epoch_G_Loss:61.1899\n",
      "timer:  54.3267 sec.\n",
      "-------------\n",
      "Epoch 63/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 63 || Epoch_D_Loss:0.0693 ||Epoch_G_Loss:57.6891\n",
      "timer:  56.1461 sec.\n",
      "-------------\n",
      "Epoch 64/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 64 || Epoch_D_Loss:0.0785 ||Epoch_G_Loss:56.6212\n",
      "timer:  56.8987 sec.\n",
      "-------------\n",
      "Epoch 65/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 65 || Epoch_D_Loss:0.0731 ||Epoch_G_Loss:55.5166\n",
      "timer:  54.6279 sec.\n",
      "-------------\n",
      "Epoch 66/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 66 || Epoch_D_Loss:0.0636 ||Epoch_G_Loss:59.4104\n",
      "timer:  55.5044 sec.\n",
      "-------------\n",
      "Epoch 67/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 67 || Epoch_D_Loss:0.0636 ||Epoch_G_Loss:62.1676\n",
      "timer:  53.6829 sec.\n",
      "-------------\n",
      "Epoch 68/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 68 || Epoch_D_Loss:0.0860 ||Epoch_G_Loss:56.0836\n",
      "timer:  53.6956 sec.\n",
      "-------------\n",
      "Epoch 69/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 69 || Epoch_D_Loss:0.0507 ||Epoch_G_Loss:61.4231\n",
      "timer:  53.0146 sec.\n",
      "-------------\n",
      "Epoch 70/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 70 || Epoch_D_Loss:0.0803 ||Epoch_G_Loss:62.9241\n",
      "timer:  53.8892 sec.\n",
      "-------------\n",
      "Epoch 71/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 71 || Epoch_D_Loss:0.0438 ||Epoch_G_Loss:58.1556\n",
      "timer:  54.2556 sec.\n",
      "-------------\n",
      "Epoch 72/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 72 || Epoch_D_Loss:0.0698 ||Epoch_G_Loss:59.3628\n",
      "timer:  58.8793 sec.\n",
      "-------------\n",
      "Epoch 73/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 73 || Epoch_D_Loss:0.0850 ||Epoch_G_Loss:59.8511\n",
      "timer:  60.4163 sec.\n",
      "-------------\n",
      "Epoch 74/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 74 || Epoch_D_Loss:0.0700 ||Epoch_G_Loss:61.3273\n",
      "timer:  59.3130 sec.\n",
      "-------------\n",
      "Epoch 75/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 75 || Epoch_D_Loss:0.0533 ||Epoch_G_Loss:62.0547\n",
      "timer:  61.2925 sec.\n",
      "-------------\n",
      "Epoch 76/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 76 || Epoch_D_Loss:0.0665 ||Epoch_G_Loss:63.9394\n",
      "timer:  62.1364 sec.\n",
      "-------------\n",
      "Epoch 77/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 77 || Epoch_D_Loss:0.0835 ||Epoch_G_Loss:59.6825\n",
      "timer:  61.8057 sec.\n",
      "-------------\n",
      "Epoch 78/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 78 || Epoch_D_Loss:0.0599 ||Epoch_G_Loss:60.6609\n",
      "timer:  61.8291 sec.\n",
      "-------------\n",
      "Epoch 79/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 79 || Epoch_D_Loss:0.0543 ||Epoch_G_Loss:61.2141\n",
      "timer:  60.2948 sec.\n",
      "-------------\n",
      "Epoch 80/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 80 || Epoch_D_Loss:0.0600 ||Epoch_G_Loss:61.5816\n",
      "timer:  61.5961 sec.\n",
      "-------------\n",
      "Epoch 81/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 81 || Epoch_D_Loss:0.0664 ||Epoch_G_Loss:63.3881\n",
      "timer:  58.8719 sec.\n",
      "-------------\n",
      "Epoch 82/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 82 || Epoch_D_Loss:0.0593 ||Epoch_G_Loss:59.4919\n",
      "timer:  60.4631 sec.\n",
      "-------------\n",
      "Epoch 83/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 83 || Epoch_D_Loss:0.0909 ||Epoch_G_Loss:64.4329\n",
      "timer:  56.6125 sec.\n",
      "-------------\n",
      "Epoch 84/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 84 || Epoch_D_Loss:0.0365 ||Epoch_G_Loss:58.8299\n",
      "timer:  59.1231 sec.\n",
      "-------------\n",
      "Epoch 85/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 85 || Epoch_D_Loss:0.0955 ||Epoch_G_Loss:64.0436\n",
      "timer:  61.6167 sec.\n",
      "-------------\n",
      "Epoch 86/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 86 || Epoch_D_Loss:0.0553 ||Epoch_G_Loss:61.5142\n",
      "timer:  59.8618 sec.\n",
      "-------------\n",
      "Epoch 87/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 87 || Epoch_D_Loss:0.0766 ||Epoch_G_Loss:61.8494\n",
      "timer:  65.9189 sec.\n",
      "-------------\n",
      "Epoch 88/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 88 || Epoch_D_Loss:0.0735 ||Epoch_G_Loss:60.5487\n",
      "timer:  60.9989 sec.\n",
      "-------------\n",
      "Epoch 89/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 89 || Epoch_D_Loss:0.0455 ||Epoch_G_Loss:62.8054\n",
      "timer:  61.2047 sec.\n",
      "-------------\n",
      "Epoch 90/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 90 || Epoch_D_Loss:0.0781 ||Epoch_G_Loss:58.5532\n",
      "timer:  60.9909 sec.\n",
      "-------------\n",
      "Epoch 91/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 91 || Epoch_D_Loss:0.0523 ||Epoch_G_Loss:63.6727\n",
      "timer:  59.6946 sec.\n",
      "-------------\n",
      "Epoch 92/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 92 || Epoch_D_Loss:0.0760 ||Epoch_G_Loss:60.9704\n",
      "timer:  58.9853 sec.\n",
      "-------------\n",
      "Epoch 93/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 93 || Epoch_D_Loss:0.0789 ||Epoch_G_Loss:60.0315\n",
      "timer:  60.5050 sec.\n",
      "-------------\n",
      "Epoch 94/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 94 || Epoch_D_Loss:0.0631 ||Epoch_G_Loss:60.9634\n",
      "timer:  57.9194 sec.\n",
      "-------------\n",
      "Epoch 95/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 95 || Epoch_D_Loss:0.0585 ||Epoch_G_Loss:62.0347\n",
      "timer:  60.1010 sec.\n",
      "-------------\n",
      "Epoch 96/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 96 || Epoch_D_Loss:0.0591 ||Epoch_G_Loss:63.6374\n",
      "timer:  57.4122 sec.\n",
      "-------------\n",
      "Epoch 97/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 97 || Epoch_D_Loss:0.0824 ||Epoch_G_Loss:67.2049\n",
      "timer:  53.5961 sec.\n",
      "-------------\n",
      "Epoch 98/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 98 || Epoch_D_Loss:0.0525 ||Epoch_G_Loss:60.3283\n",
      "timer:  44.0502 sec.\n",
      "-------------\n",
      "Epoch 99/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 99 || Epoch_D_Loss:0.0588 ||Epoch_G_Loss:63.1762\n",
      "timer:  44.5465 sec.\n",
      "-------------\n",
      "Epoch 100/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 100 || Epoch_D_Loss:0.0677 ||Epoch_G_Loss:62.8843\n",
      "timer:  44.6930 sec.\n",
      "-------------\n",
      "Epoch 101/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 101 || Epoch_D_Loss:0.0603 ||Epoch_G_Loss:63.4149\n",
      "timer:  44.7359 sec.\n",
      "-------------\n",
      "Epoch 102/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 102 || Epoch_D_Loss:0.0796 ||Epoch_G_Loss:63.7666\n",
      "timer:  43.8541 sec.\n",
      "-------------\n",
      "Epoch 103/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 103 || Epoch_D_Loss:0.0475 ||Epoch_G_Loss:61.1547\n",
      "timer:  44.3612 sec.\n",
      "-------------\n",
      "Epoch 104/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 104 || Epoch_D_Loss:0.0785 ||Epoch_G_Loss:59.5902\n",
      "timer:  53.4197 sec.\n",
      "-------------\n",
      "Epoch 105/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 105 || Epoch_D_Loss:0.0603 ||Epoch_G_Loss:64.9090\n",
      "timer:  51.5447 sec.\n",
      "-------------\n",
      "Epoch 106/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 106 || Epoch_D_Loss:0.0684 ||Epoch_G_Loss:64.0901\n",
      "timer:  51.3908 sec.\n",
      "-------------\n",
      "Epoch 107/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 107 || Epoch_D_Loss:0.0493 ||Epoch_G_Loss:62.7203\n",
      "timer:  49.7607 sec.\n",
      "-------------\n",
      "Epoch 108/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 108 || Epoch_D_Loss:0.0628 ||Epoch_G_Loss:61.6657\n",
      "timer:  49.8208 sec.\n",
      "-------------\n",
      "Epoch 109/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 109 || Epoch_D_Loss:0.0897 ||Epoch_G_Loss:61.7704\n",
      "timer:  52.7879 sec.\n",
      "-------------\n",
      "Epoch 110/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 110 || Epoch_D_Loss:0.0361 ||Epoch_G_Loss:58.2128\n",
      "timer:  51.2928 sec.\n",
      "-------------\n",
      "Epoch 111/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 111 || Epoch_D_Loss:0.0699 ||Epoch_G_Loss:63.2527\n",
      "timer:  51.0672 sec.\n",
      "-------------\n",
      "Epoch 112/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 112 || Epoch_D_Loss:0.0963 ||Epoch_G_Loss:63.2700\n",
      "timer:  48.6000 sec.\n",
      "-------------\n",
      "Epoch 113/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 113 || Epoch_D_Loss:0.0338 ||Epoch_G_Loss:59.3958\n",
      "timer:  50.8243 sec.\n",
      "-------------\n",
      "Epoch 114/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 114 || Epoch_D_Loss:0.0508 ||Epoch_G_Loss:65.5742\n",
      "timer:  51.7076 sec.\n",
      "-------------\n",
      "Epoch 115/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 115 || Epoch_D_Loss:0.0717 ||Epoch_G_Loss:64.7457\n",
      "timer:  49.8414 sec.\n",
      "-------------\n",
      "Epoch 116/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 116 || Epoch_D_Loss:0.0453 ||Epoch_G_Loss:65.8495\n",
      "timer:  50.4177 sec.\n",
      "-------------\n",
      "Epoch 117/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 117 || Epoch_D_Loss:0.0824 ||Epoch_G_Loss:61.8034\n",
      "timer:  51.8505 sec.\n",
      "-------------\n",
      "Epoch 118/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 118 || Epoch_D_Loss:0.0496 ||Epoch_G_Loss:66.0396\n",
      "timer:  51.1095 sec.\n",
      "-------------\n",
      "Epoch 119/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 119 || Epoch_D_Loss:0.0707 ||Epoch_G_Loss:63.3173\n",
      "timer:  50.1562 sec.\n",
      "-------------\n",
      "Epoch 120/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 120 || Epoch_D_Loss:0.0569 ||Epoch_G_Loss:64.8354\n",
      "timer:  56.5741 sec.\n",
      "-------------\n",
      "Epoch 121/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 121 || Epoch_D_Loss:0.0508 ||Epoch_G_Loss:64.9974\n",
      "timer:  49.5344 sec.\n",
      "-------------\n",
      "Epoch 122/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 122 || Epoch_D_Loss:0.0715 ||Epoch_G_Loss:65.8770\n",
      "timer:  51.3577 sec.\n",
      "-------------\n",
      "Epoch 123/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 123 || Epoch_D_Loss:0.0719 ||Epoch_G_Loss:64.5577\n",
      "timer:  50.5177 sec.\n",
      "-------------\n",
      "Epoch 124/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 124 || Epoch_D_Loss:0.0538 ||Epoch_G_Loss:64.0182\n",
      "timer:  52.6400 sec.\n",
      "-------------\n",
      "Epoch 125/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 125 || Epoch_D_Loss:0.0600 ||Epoch_G_Loss:61.6615\n",
      "timer:  52.1509 sec.\n",
      "-------------\n",
      "Epoch 126/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 126 || Epoch_D_Loss:0.0530 ||Epoch_G_Loss:65.9493\n",
      "timer:  52.0493 sec.\n",
      "-------------\n",
      "Epoch 127/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 127 || Epoch_D_Loss:0.0675 ||Epoch_G_Loss:65.1729\n",
      "timer:  53.7069 sec.\n",
      "-------------\n",
      "Epoch 128/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 128 || Epoch_D_Loss:0.0410 ||Epoch_G_Loss:68.5972\n",
      "timer:  53.3844 sec.\n",
      "-------------\n",
      "Epoch 129/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 129 || Epoch_D_Loss:0.0593 ||Epoch_G_Loss:66.5147\n",
      "timer:  56.5076 sec.\n",
      "-------------\n",
      "Epoch 130/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 130 || Epoch_D_Loss:0.0484 ||Epoch_G_Loss:69.7026\n",
      "timer:  59.4652 sec.\n",
      "-------------\n",
      "Epoch 131/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 131 || Epoch_D_Loss:0.0460 ||Epoch_G_Loss:65.2952\n",
      "timer:  60.2843 sec.\n",
      "-------------\n",
      "Epoch 132/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 132 || Epoch_D_Loss:0.0579 ||Epoch_G_Loss:68.6068\n",
      "timer:  61.0747 sec.\n",
      "-------------\n",
      "Epoch 133/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 133 || Epoch_D_Loss:0.0559 ||Epoch_G_Loss:70.8209\n",
      "timer:  60.9319 sec.\n",
      "-------------\n",
      "Epoch 134/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 134 || Epoch_D_Loss:0.0576 ||Epoch_G_Loss:68.1472\n",
      "timer:  59.2251 sec.\n",
      "-------------\n",
      "Epoch 135/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 135 || Epoch_D_Loss:0.0511 ||Epoch_G_Loss:67.9684\n",
      "timer:  66.4007 sec.\n",
      "-------------\n",
      "Epoch 136/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 136 || Epoch_D_Loss:0.0719 ||Epoch_G_Loss:65.6278\n",
      "timer:  64.4866 sec.\n",
      "-------------\n",
      "Epoch 137/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 137 || Epoch_D_Loss:0.0627 ||Epoch_G_Loss:65.6074\n",
      "timer:  61.5074 sec.\n",
      "-------------\n",
      "Epoch 138/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 138 || Epoch_D_Loss:0.0547 ||Epoch_G_Loss:64.8368\n",
      "timer:  60.4007 sec.\n",
      "-------------\n",
      "Epoch 139/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 139 || Epoch_D_Loss:0.0595 ||Epoch_G_Loss:67.4961\n",
      "timer:  63.2521 sec.\n",
      "-------------\n",
      "Epoch 140/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 140 || Epoch_D_Loss:0.0516 ||Epoch_G_Loss:69.7726\n",
      "timer:  60.9150 sec.\n",
      "-------------\n",
      "Epoch 141/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 141 || Epoch_D_Loss:0.0510 ||Epoch_G_Loss:66.2161\n",
      "timer:  60.5025 sec.\n",
      "-------------\n",
      "Epoch 142/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 142 || Epoch_D_Loss:0.0861 ||Epoch_G_Loss:66.3179\n",
      "timer:  61.2032 sec.\n",
      "-------------\n",
      "Epoch 143/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 143 || Epoch_D_Loss:0.0280 ||Epoch_G_Loss:69.3663\n",
      "timer:  59.8932 sec.\n",
      "-------------\n",
      "Epoch 144/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 144 || Epoch_D_Loss:0.0583 ||Epoch_G_Loss:70.5911\n",
      "timer:  58.7149 sec.\n",
      "-------------\n",
      "Epoch 145/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 145 || Epoch_D_Loss:0.0790 ||Epoch_G_Loss:62.9753\n",
      "timer:  63.4625 sec.\n",
      "-------------\n",
      "Epoch 146/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 146 || Epoch_D_Loss:0.0635 ||Epoch_G_Loss:63.6949\n",
      "timer:  60.4414 sec.\n",
      "-------------\n",
      "Epoch 147/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 147 || Epoch_D_Loss:0.0243 ||Epoch_G_Loss:67.9741\n",
      "timer:  59.9631 sec.\n",
      "-------------\n",
      "Epoch 148/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 148 || Epoch_D_Loss:0.0754 ||Epoch_G_Loss:70.8741\n",
      "timer:  59.7700 sec.\n",
      "-------------\n",
      "Epoch 149/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 149 || Epoch_D_Loss:0.0515 ||Epoch_G_Loss:68.7961\n",
      "timer:  59.0249 sec.\n",
      "-------------\n",
      "Epoch 150/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 150 || Epoch_D_Loss:0.0590 ||Epoch_G_Loss:70.2806\n",
      "timer:  69.8195 sec.\n",
      "-------------\n",
      "Epoch 151/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 151 || Epoch_D_Loss:0.0544 ||Epoch_G_Loss:69.2957\n",
      "timer:  68.5516 sec.\n",
      "-------------\n",
      "Epoch 152/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 152 || Epoch_D_Loss:0.0572 ||Epoch_G_Loss:67.0064\n",
      "timer:  64.6946 sec.\n",
      "-------------\n",
      "Epoch 153/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 153 || Epoch_D_Loss:0.0790 ||Epoch_G_Loss:67.6453\n",
      "timer:  62.9754 sec.\n",
      "-------------\n",
      "Epoch 154/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 154 || Epoch_D_Loss:0.0457 ||Epoch_G_Loss:68.3254\n",
      "timer:  60.8105 sec.\n",
      "-------------\n",
      "Epoch 155/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 155 || Epoch_D_Loss:0.0564 ||Epoch_G_Loss:66.0507\n",
      "timer:  61.0349 sec.\n",
      "-------------\n",
      "Epoch 156/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 156 || Epoch_D_Loss:0.0483 ||Epoch_G_Loss:68.7503\n",
      "timer:  68.1897 sec.\n",
      "-------------\n",
      "Epoch 157/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 157 || Epoch_D_Loss:0.0598 ||Epoch_G_Loss:73.3381\n",
      "timer:  65.6688 sec.\n",
      "-------------\n",
      "Epoch 158/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 158 || Epoch_D_Loss:0.0765 ||Epoch_G_Loss:66.8384\n",
      "timer:  57.8400 sec.\n",
      "-------------\n",
      "Epoch 159/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 159 || Epoch_D_Loss:0.0466 ||Epoch_G_Loss:67.9582\n",
      "timer:  56.3015 sec.\n",
      "-------------\n",
      "Epoch 160/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 160 || Epoch_D_Loss:0.0641 ||Epoch_G_Loss:69.2479\n",
      "timer:  58.2782 sec.\n",
      "-------------\n",
      "Epoch 161/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 161 || Epoch_D_Loss:0.0384 ||Epoch_G_Loss:69.1004\n",
      "timer:  59.4892 sec.\n",
      "-------------\n",
      "Epoch 162/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 162 || Epoch_D_Loss:0.0561 ||Epoch_G_Loss:69.4816\n",
      "timer:  55.4127 sec.\n",
      "-------------\n",
      "Epoch 163/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 163 || Epoch_D_Loss:0.0762 ||Epoch_G_Loss:67.1761\n",
      "timer:  54.9304 sec.\n",
      "-------------\n",
      "Epoch 164/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 164 || Epoch_D_Loss:0.0548 ||Epoch_G_Loss:63.0282\n",
      "timer:  59.6351 sec.\n",
      "-------------\n",
      "Epoch 165/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 165 || Epoch_D_Loss:0.0580 ||Epoch_G_Loss:64.7787\n",
      "timer:  60.0149 sec.\n",
      "-------------\n",
      "Epoch 166/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 166 || Epoch_D_Loss:0.0419 ||Epoch_G_Loss:71.1224\n",
      "timer:  54.2404 sec.\n",
      "-------------\n",
      "Epoch 167/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 167 || Epoch_D_Loss:0.0484 ||Epoch_G_Loss:74.1331\n",
      "timer:  56.8232 sec.\n",
      "-------------\n",
      "Epoch 168/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 168 || Epoch_D_Loss:0.0773 ||Epoch_G_Loss:70.6350\n",
      "timer:  55.7843 sec.\n",
      "-------------\n",
      "Epoch 169/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 169 || Epoch_D_Loss:0.0423 ||Epoch_G_Loss:73.6327\n",
      "timer:  55.3266 sec.\n",
      "-------------\n",
      "Epoch 170/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 170 || Epoch_D_Loss:0.0507 ||Epoch_G_Loss:75.6807\n",
      "timer:  56.8950 sec.\n",
      "-------------\n",
      "Epoch 171/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 171 || Epoch_D_Loss:0.0597 ||Epoch_G_Loss:70.7741\n",
      "timer:  56.6780 sec.\n",
      "-------------\n",
      "Epoch 172/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 172 || Epoch_D_Loss:0.0627 ||Epoch_G_Loss:74.5655\n",
      "timer:  54.6223 sec.\n",
      "-------------\n",
      "Epoch 173/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 173 || Epoch_D_Loss:0.0445 ||Epoch_G_Loss:71.2960\n",
      "timer:  55.2156 sec.\n",
      "-------------\n",
      "Epoch 174/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 174 || Epoch_D_Loss:0.0339 ||Epoch_G_Loss:74.9085\n",
      "timer:  55.9783 sec.\n",
      "-------------\n",
      "Epoch 175/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 175 || Epoch_D_Loss:0.0650 ||Epoch_G_Loss:69.9690\n",
      "timer:  55.0644 sec.\n",
      "-------------\n",
      "Epoch 176/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 176 || Epoch_D_Loss:0.0519 ||Epoch_G_Loss:71.9772\n",
      "timer:  58.9358 sec.\n",
      "-------------\n",
      "Epoch 177/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 177 || Epoch_D_Loss:0.0627 ||Epoch_G_Loss:74.0605\n",
      "timer:  54.2339 sec.\n",
      "-------------\n",
      "Epoch 178/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 178 || Epoch_D_Loss:0.0462 ||Epoch_G_Loss:72.3381\n",
      "timer:  54.6064 sec.\n",
      "-------------\n",
      "Epoch 179/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 179 || Epoch_D_Loss:0.0435 ||Epoch_G_Loss:74.6832\n",
      "timer:  56.0755 sec.\n",
      "-------------\n",
      "Epoch 180/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 180 || Epoch_D_Loss:0.0604 ||Epoch_G_Loss:79.4513\n",
      "timer:  54.3603 sec.\n",
      "-------------\n",
      "Epoch 181/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 181 || Epoch_D_Loss:0.0649 ||Epoch_G_Loss:75.5268\n",
      "timer:  53.9724 sec.\n",
      "-------------\n",
      "Epoch 182/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 182 || Epoch_D_Loss:0.0461 ||Epoch_G_Loss:71.9848\n",
      "timer:  54.1851 sec.\n",
      "-------------\n",
      "Epoch 183/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 183 || Epoch_D_Loss:0.0661 ||Epoch_G_Loss:72.3351\n",
      "timer:  56.0977 sec.\n",
      "-------------\n",
      "Epoch 184/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 184 || Epoch_D_Loss:0.0674 ||Epoch_G_Loss:72.1960\n",
      "timer:  55.0023 sec.\n",
      "-------------\n",
      "Epoch 185/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 185 || Epoch_D_Loss:0.0408 ||Epoch_G_Loss:67.0046\n",
      "timer:  54.5272 sec.\n",
      "-------------\n",
      "Epoch 186/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 186 || Epoch_D_Loss:0.0727 ||Epoch_G_Loss:73.3579\n",
      "timer:  55.9383 sec.\n",
      "-------------\n",
      "Epoch 187/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 187 || Epoch_D_Loss:0.0437 ||Epoch_G_Loss:69.3881\n",
      "timer:  56.6221 sec.\n",
      "-------------\n",
      "Epoch 188/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 188 || Epoch_D_Loss:0.0622 ||Epoch_G_Loss:74.7581\n",
      "timer:  54.0765 sec.\n",
      "-------------\n",
      "Epoch 189/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 189 || Epoch_D_Loss:0.0561 ||Epoch_G_Loss:66.1543\n",
      "timer:  54.4433 sec.\n",
      "-------------\n",
      "Epoch 190/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 190 || Epoch_D_Loss:0.0439 ||Epoch_G_Loss:72.7499\n",
      "timer:  55.4869 sec.\n",
      "-------------\n",
      "Epoch 191/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 191 || Epoch_D_Loss:0.0533 ||Epoch_G_Loss:75.2139\n",
      "timer:  54.9198 sec.\n",
      "-------------\n",
      "Epoch 192/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 192 || Epoch_D_Loss:0.0621 ||Epoch_G_Loss:71.3196\n",
      "timer:  54.1955 sec.\n",
      "-------------\n",
      "Epoch 193/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 193 || Epoch_D_Loss:0.0470 ||Epoch_G_Loss:74.4079\n",
      "timer:  54.2701 sec.\n",
      "-------------\n",
      "Epoch 194/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 194 || Epoch_D_Loss:0.0380 ||Epoch_G_Loss:77.4917\n",
      "timer:  55.6517 sec.\n",
      "-------------\n",
      "Epoch 195/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 195 || Epoch_D_Loss:0.0515 ||Epoch_G_Loss:71.7696\n",
      "timer:  55.5341 sec.\n",
      "-------------\n",
      "Epoch 196/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 196 || Epoch_D_Loss:0.0609 ||Epoch_G_Loss:73.6432\n",
      "timer:  56.4210 sec.\n",
      "-------------\n",
      "Epoch 197/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 197 || Epoch_D_Loss:0.0572 ||Epoch_G_Loss:68.9410\n",
      "timer:  54.7988 sec.\n",
      "-------------\n",
      "Epoch 198/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 198 || Epoch_D_Loss:0.0612 ||Epoch_G_Loss:71.5950\n",
      "timer:  55.8703 sec.\n",
      "-------------\n",
      "Epoch 199/200\n",
      "-------------\n",
      "（train）\n",
      "-------------\n",
      "epoch 199 || Epoch_D_Loss:0.0624 ||Epoch_G_Loss:69.1306\n",
      "timer:  64.0041 sec.\n"
     ]
    }
   ],
   "source": [
    "# 学習・検証の実施\n",
    "num_epochs = 200\n",
    "outf = './result_emnist'\n",
    "G_update, D_update = train_model(net_G, net_D, dataloader=train_dataloader, num_epochs=num_epochs, mini_batch_size=mini_batch_size, z_dim=z_dim, device=device, outf=outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 36, 51, 51, 60, 23, 40, 58, 34, 40, 36, 53]\n"
     ]
    }
   ],
   "source": [
    "fake_label_list = []\n",
    "s = \"HappyNewYear\"\n",
    "for i in range(len(s)):\n",
    "    fake_label_list.append(label_list.index(s[i]))\n",
    "print(fake_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils\n",
    "z_dim = 100\n",
    "sample_noise = torch.randn(len(fake_label_list), z_dim, 1 ,1, device=device)\n",
    "sample_label = torch.tensor(fake_label_list, dtype=torch.long, device=device) #torch.longはint64を指す\n",
    "fake_noise_label = concat_noise_label(sample_noise, sample_label, device) #ノイズとラベルを連結\n",
    "fake_image = net_G(fake_noise_label)\n",
    "vutils.save_image(fake_image, './fake_sample.png'.format(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56bfe93c118d2597f708334f8826861ef9014b7ce58ae7f669aaf467c5667e00"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
